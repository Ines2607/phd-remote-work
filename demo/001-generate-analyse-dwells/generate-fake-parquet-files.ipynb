{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Fake Parquet Files for Testing\n",
        "\n",
        "This notebook generates synthetic parquet files that mimic the structure of real dwells data for testing the outlier detection analysis.\n",
        "\n",
        "## Data Structure\n",
        "\n",
        "The generated parquet files contain the following columns (matching BigQuery table structure):\n",
        "\n",
        "### Required Columns:\n",
        "- **identifier**: Unique user identifier (string, format: `user_YYYYMM_XXXXXX`)\n",
        "- **identifier_type**: Type of identifier - either 'GAID' (Android) or 'IDFA' (iOS)\n",
        "- **date**: Date of the dwell event (datetime, within the specified month)\n",
        "- **timestamp**: Full timestamp of the dwell event (datetime)\n",
        "- **duration_seconds**: Duration of the dwell in seconds (int, minimum 180 seconds)\n",
        "- **centroid_latitude**: Latitude coordinate (float, around Tel Aviv area: ~32.0853)\n",
        "- **centroid_longitude**: Longitude coordinate (float, around Tel Aviv area: ~34.7818)\n",
        "- **classification**: Type of dwell event - 'DWELL', 'AREA_DWELL', or 'STOP'\n",
        "- **bump_count**: Number of location updates during the dwell (int, 0-5)\n",
        "\n",
        "### Derived Columns (calculated automatically):\n",
        "- **duration_hours**: Calculated from duration_seconds / 3600\n",
        "- **geohash**: Calculated from latitude/longitude using pygeohash (precision=7)\n",
        "- **flag_night**: Boolean flag for night hours (20:00-03:59)\n",
        "- **flag_work_hours**: Boolean flag for work hours (08:00-17:59)\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Set the output folder and months to generate\n",
        "2. Adjust parameters (number of users, dwells per user range)\n",
        "3. Run the generator\n",
        "4. Use the generated files in `demo-outlier-detection-parquet.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports loaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from datetime import timedelta\n",
        "import pygeohash\n",
        "\n",
        "print(\"Imports loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set the output folder and months to generate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Output folder: data/test_parquet_files\n",
            "  Months to generate: 6 months\n",
            "  Users per month: 500\n",
            "  Dwells per user: 2-30\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "OUTPUT_FOLDER = \"data/test_parquet_files\"  # Folder to save generated parquet files\n",
        "\n",
        "# Months to generate (format: YYYYMM)\n",
        "MONTHS = ['202001', '202002', '202003', '202004', '202005', '202006']\n",
        "\n",
        "# Data generation parameters\n",
        "NUM_USERS_PER_MONTH = 500  # Number of unique users per month\n",
        "DWELLS_PER_USER_RANGE = (2, 30)  # Min and max dwells per user\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
        "print(f\"  Months to generate: {len(MONTHS)} months\")\n",
        "print(f\"  Users per month: {NUM_USERS_PER_MONTH}\")\n",
        "print(f\"  Dwells per user: {DWELLS_PER_USER_RANGE[0]}-{DWELLS_PER_USER_RANGE[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generator Function\n",
        "\n",
        "Function to generate fake parquet files with realistic dwells data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_fake_parquet_files(output_folder, months, num_users_per_month=1000, dwells_per_user_range=(1, 50)):\n",
        "    \"\"\"\n",
        "    Generate fake parquet files for testing outlier detection analysis.\n",
        "    \n",
        "    This function creates synthetic dwells data that mimics the structure of real data\n",
        "    from the BigQuery table `phd_dwells.dwells_monthly_fltrd`. The generated data includes:\n",
        "    \n",
        "    - Multiple users per month (with unique identifiers)\n",
        "    - Multiple dwells per user (varying counts)\n",
        "    - Realistic timestamps and dates within each month\n",
        "    - Geographic coordinates around Tel Aviv, Israel\n",
        "    - Duration values (minimum 180 seconds as per filtering)\n",
        "    - Classification types and bump counts\n",
        "    \n",
        "    The generated files can be used to test the outlier detection notebook\n",
        "    (`demo-outlier-detection-parquet.ipynb`) without needing access to BigQuery or real data.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    output_folder : str\n",
        "        Path to folder where parquet files will be saved. Will be created if it doesn't exist.\n",
        "        \n",
        "    months : list of str\n",
        "        List of month identifiers in YYYYMM format (e.g., ['202001', '202002', '202003']).\n",
        "        Each month will generate a separate parquet file named {month}.parquet.\n",
        "        \n",
        "    num_users_per_month : int, default=1000\n",
        "        Number of unique users to generate for each month. Each user will have\n",
        "        a unique identifier and multiple dwell events.\n",
        "        \n",
        "    dwells_per_user_range : tuple of (int, int), default=(1, 50)\n",
        "        Range of dwell counts per user. Each user will have a random number of dwells\n",
        "        between the minimum and maximum values (inclusive).\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Files are saved to disk. Prints progress and summary.\n",
        "        \n",
        "    Generated File Format\n",
        "    ---------------------\n",
        "    Each parquet file contains a DataFrame with the following columns:\n",
        "    \n",
        "    - identifier (str): Unique user ID, format: 'user_{month}_{index:06d}'\n",
        "    - identifier_type (str): Either 'GAID' (Android) or 'IDFA' (iOS), randomly assigned\n",
        "    - date (datetime): Date of the dwell event (within the specified month)\n",
        "    - timestamp (datetime): Full timestamp including time of day\n",
        "    - duration_seconds (int): Duration in seconds, range: 180 to 28800 (8 hours)\n",
        "    - centroid_latitude (float): Latitude coordinate, centered around Tel Aviv (~32.0853)\n",
        "    - centroid_longitude (float): Longitude coordinate, centered around Tel Aviv (~34.7818)\n",
        "    - classification (str): Randomly selected from ['DWELL', 'AREA_DWELL', 'STOP']\n",
        "    - bump_count (int): Number of location updates, range: 0 to 5\n",
        "    \n",
        "    Notes\n",
        "    -----\n",
        "    - Geographic coordinates are randomly distributed within ~0.1 degrees of Tel Aviv center\n",
        "    - Timestamps are randomly distributed throughout each day\n",
        "    - Dates are randomly selected from days 1-28 of each month (to avoid month-end issues)\n",
        "    - Duration values respect the minimum 180 seconds filter used in real data processing\n",
        "    \n",
        "    Examples\n",
        "    --------\n",
        "    >>> # Generate 6 months of test data\n",
        "    >>> months = ['202001', '202002', '202003', '202004', '202005', '202006']\n",
        "    >>> generate_fake_parquet_files('data/test', months, num_users_per_month=500)\n",
        "    \n",
        "    >>> # Generate a single month with many users\n",
        "    >>> generate_fake_parquet_files('data/test', ['202001'], num_users_per_month=2000)\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    \n",
        "    # Israel coordinates (Tel Aviv area)\n",
        "    base_lat = 32.0853\n",
        "    base_lon = 34.7818\n",
        "    \n",
        "    total_dwells = 0\n",
        "    \n",
        "    for month in months:\n",
        "        print(f\"Generating fake data for {month}...\")\n",
        "        \n",
        "        # Parse month\n",
        "        year = int(month[:4])\n",
        "        month_num = int(month[4:6])\n",
        "        \n",
        "        all_dwells = []\n",
        "        \n",
        "        # Generate users\n",
        "        for user_idx in range(num_users_per_month):\n",
        "            identifier = f\"user_{month}_{user_idx:06d}\"\n",
        "            identifier_type = random.choice(['GAID', 'IDFA'])\n",
        "            \n",
        "            # Number of dwells for this user\n",
        "            num_dwells = random.randint(dwells_per_user_range[0], dwells_per_user_range[1])\n",
        "            \n",
        "            # Generate dwells for this user\n",
        "            for dwell_idx in range(num_dwells):\n",
        "                # Random date within the month\n",
        "                day = random.randint(1, 28)  # Use 28 to avoid month-end issues\n",
        "                date = pd.Timestamp(year, month_num, day)\n",
        "                \n",
        "                # Random timestamp within the day\n",
        "                hour = random.randint(0, 23)\n",
        "                minute = random.randint(0, 59)\n",
        "                timestamp = date.replace(hour=hour, minute=minute)\n",
        "                \n",
        "                # Random duration (in seconds, minimum 180)\n",
        "                duration_seconds = random.randint(180, 8 * 3600)  # 3 min to 8 hours\n",
        "                \n",
        "                # Random location (around Tel Aviv)\n",
        "                lat = base_lat + random.uniform(-0.1, 0.1)\n",
        "                lon = base_lon + random.uniform(-0.1, 0.1)\n",
        "                \n",
        "                # Random classification\n",
        "                classification = random.choice(['DWELL', 'AREA_DWELL', 'STOP'])\n",
        "                \n",
        "                # Random bump count\n",
        "                bump_count = random.randint(0, 5)\n",
        "                \n",
        "                dwell = {\n",
        "                    'identifier': identifier,\n",
        "                    'identifier_type': identifier_type,\n",
        "                    'date': date,\n",
        "                    'timestamp': timestamp,\n",
        "                    'duration_seconds': duration_seconds,\n",
        "                    'centroid_latitude': lat,\n",
        "                    'centroid_longitude': lon,\n",
        "                    'classification': classification,\n",
        "                    'bump_count': bump_count,\n",
        "                }\n",
        "                \n",
        "                all_dwells.append(dwell)\n",
        "        \n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(all_dwells)\n",
        "        total_dwells += len(df)\n",
        "        \n",
        "        # Save as parquet\n",
        "        filename = f\"{month}.parquet\"\n",
        "        filepath = os.path.join(output_folder, filename)\n",
        "        df.to_parquet(filepath, index=False)\n",
        "        \n",
        "        print(f\"  ✓ Saved {len(df):,} dwells to {filename}\")\n",
        "        print(f\"    - {df['identifier'].nunique():,} unique users\")\n",
        "        print(f\"    - Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"✓ Generated {len(months)} parquet files in {output_folder}\")\n",
        "    print(f\"  Total dwells: {total_dwells:,}\")\n",
        "    print(f\"  Total users: {len(months) * num_users_per_month:,}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"\\nTo use these files, update PARQUET_FOLDER in demo-outlier-detection-parquet.ipynb to:\")\n",
        "    print(f\"  {os.path.abspath(output_folder)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating fake data for 202001...\n",
            "  ✓ Saved 8,122 dwells to 202001.parquet\n",
            "    - 500 unique users\n",
            "    - Date range: 2020-01-01 to 2020-01-28\n",
            "Generating fake data for 202002...\n",
            "  ✓ Saved 8,015 dwells to 202002.parquet\n",
            "    - 500 unique users\n",
            "    - Date range: 2020-02-01 to 2020-02-28\n",
            "Generating fake data for 202003...\n",
            "  ✓ Saved 8,199 dwells to 202003.parquet\n",
            "    - 500 unique users\n",
            "    - Date range: 2020-03-01 to 2020-03-28\n",
            "Generating fake data for 202004...\n",
            "  ✓ Saved 8,408 dwells to 202004.parquet\n",
            "    - 500 unique users\n",
            "    - Date range: 2020-04-01 to 2020-04-28\n",
            "Generating fake data for 202005...\n",
            "  ✓ Saved 7,916 dwells to 202005.parquet\n",
            "    - 500 unique users\n",
            "    - Date range: 2020-05-01 to 2020-05-28\n",
            "Generating fake data for 202006...\n",
            "  ✓ Saved 8,127 dwells to 202006.parquet\n",
            "    - 500 unique users\n",
            "    - Date range: 2020-06-01 to 2020-06-28\n",
            "\n",
            "============================================================\n",
            "✓ Generated 6 parquet files in data/test_parquet_files\n",
            "  Total dwells: 48,787\n",
            "  Total users: 3,000\n",
            "============================================================\n",
            "\n",
            "To use these files, update PARQUET_FOLDER in demo-outlier-detection-parquet.ipynb to:\n",
            "  /Users/inessat/Documents/phd/empirics/israel/notebooks/phd-remote-work/020-process-dwells/data/test_parquet_files\n"
          ]
        }
      ],
      "source": [
        "# Generate the fake parquet files\n",
        "generate_fake_parquet_files(\n",
        "    OUTPUT_FOLDER, \n",
        "    MONTHS, \n",
        "    num_users_per_month=NUM_USERS_PER_MONTH,\n",
        "    dwells_per_user_range=DWELLS_PER_USER_RANGE\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Generated Files\n",
        "\n",
        "Check that the files were created correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6 parquet files:\n",
            "\n",
            "202001.parquet:\n",
            "  - Rows: 8,122\n",
            "  - Columns: ['identifier', 'identifier_type', 'date', 'timestamp', 'duration_seconds', 'centroid_latitude', 'centroid_longitude', 'classification', 'bump_count']\n",
            "  - Unique users: 500\n",
            "  - Date range: 2020-01-01 to 2020-01-28\n",
            "  - Identifier types: {'IDFA': 4377, 'GAID': 3745}\n",
            "\n",
            "  Sample row:\n",
            "{'identifier': 'user_202001_000000', 'identifier_type': 'IDFA', 'date': Timestamp('2020-01-13 00:00:00'), 'timestamp': Timestamp('2020-01-13 20:59:00'), 'duration_seconds': 26440, 'centroid_latitude': 32.09231240281736, 'centroid_longitude': 34.78557187708164, 'classification': 'STOP', 'bump_count': 1}\n"
          ]
        }
      ],
      "source": [
        "# Verify files were created\n",
        "import glob\n",
        "\n",
        "parquet_files = glob.glob(os.path.join(OUTPUT_FOLDER, \"*.parquet\"))\n",
        "print(f\"Found {len(parquet_files)} parquet files:\")\n",
        "\n",
        "for file_path in sorted(parquet_files):\n",
        "    filename = os.path.basename(file_path)\n",
        "    df = pd.read_parquet(file_path)\n",
        "    print(f\"\\n{filename}:\")\n",
        "    print(f\"  - Rows: {len(df):,}\")\n",
        "    print(f\"  - Columns: {list(df.columns)}\")\n",
        "    print(f\"  - Unique users: {df['identifier'].nunique():,}\")\n",
        "    print(f\"  - Date range: {df['date'].min().date()} to {df['date'].max().date()}\")\n",
        "    print(f\"  - Identifier types: {df['identifier_type'].value_counts().to_dict()}\")\n",
        "    \n",
        "    # Show sample row\n",
        "    print(f\"\\n  Sample row:\")\n",
        "    print(df.iloc[0].to_dict())\n",
        "    break  # Just show first file as example\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "spatial_analytics_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
